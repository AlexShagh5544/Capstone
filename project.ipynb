{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28548e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization Library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "\n",
    "# Evaluation Libraries\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Encoding Library\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the configuration option to disable the warning\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "\n",
    "\n",
    "\n",
    "# Cleaning data Function\n",
    "def clean_data(df, fill_methods, numeric_columns_with_outliers, remove_outliers=False, normalization='none'):\n",
    "    # Handling missing values for selected columns\n",
    "    for column, fill_method in fill_methods.items():\n",
    "        if fill_method == 'forward_fill':\n",
    "            df[column].fillna(method='ffill', inplace=True)\n",
    "        elif fill_method == 'backward_fill':\n",
    "            df[column].fillna(method='bfill', inplace=True)\n",
    "        elif fill_method == 'mean':\n",
    "            df[column].fillna(df[column].mean(), inplace=True)\n",
    "        elif fill_method == 'median':\n",
    "            df[column].fillna(df[column].median(), inplace=True)\n",
    "        elif fill_method == 'mode':\n",
    "            df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    \n",
    "    # Handling outliers with Z-score method\n",
    "    if remove_outliers:\n",
    "        from scipy import stats\n",
    "        for column in numeric_columns_with_outliers:\n",
    "            z_scores = np.abs(stats.zscore(df[column]))\n",
    "            df = df[(z_scores < 3)]\n",
    "    \n",
    "    # Normalization or Standardization\n",
    "    if normalization == 'min_max':\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        df[df.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(df.select_dtypes(include=[np.number]))\n",
    "    elif normalization == 'standard':\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        df[df.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(df.select_dtypes(include=[np.number]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Visualization data Function based on user selections\n",
    "def generate_visualization(df, chart_type=\"histogram\", selected_columns=None, target_variable=None, colors=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    st.subheader(f\"{chart_type.capitalize()} Visualization\")\n",
    "\n",
    "    if chart_type == \"histogram\":\n",
    "        for column in selected_columns:\n",
    "            sns.histplot(df[column], ax=ax, kde=True, bins=30, color=colors)\n",
    "            plt.xlabel(column) \n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.title(f\"Histogram of {column} Column\")\n",
    "            st.pyplot(fig)\n",
    "\n",
    "    elif chart_type == \"bar chart\":\n",
    "        if target_variable and selected_columns:\n",
    "            for column in selected_columns:\n",
    "                fig, ax = plt.subplots()\n",
    "                sns.barplot(x=column, y=target_variable, data=df, ax=ax, color=colors)\n",
    "                plt.xlabel(column) \n",
    "                plt.ylabel(target_variable)\n",
    "                plt.title(f\"Bar Chart: {column} vs {target_variable}\")\n",
    "                st.pyplot(fig)\n",
    "\n",
    "    elif chart_type == \"scatter plot\":\n",
    "        if x_column and y_columns:\n",
    "            for y_column in y_columns:\n",
    "                fig, ax = plt.subplots()\n",
    "                # Check if hue_column is selected and not empty\n",
    "                if hue_column:  \n",
    "                    # a custom color palette for hue\n",
    "                    custom_palette = sns.color_palette(\"husl\", len(df[hue_column].unique()))\n",
    "                    sns.scatterplot(x=df[x_column], y=df[y_column], hue=df[hue_column], ax=ax, palette=custom_palette)\n",
    "                else:\n",
    "                    sns.scatterplot(x=df[x_column], y=df[y_column], ax=ax, color=colors)\n",
    "                plt.xlabel(x_column)\n",
    "                plt.ylabel(y_column)\n",
    "                if hue_column:\n",
    "                    plt.legend(title=hue_column)\n",
    "                plt.title(f\"Scatter Plot: {x_column} vs {y_column}\")\n",
    "                st.pyplot(fig)\n",
    "\n",
    "\n",
    "    elif chart_type == \"line chart\":\n",
    "        if target_variable and selected_columns:\n",
    "            for column in selected_columns:\n",
    "                fig, ax = plt.subplots()\n",
    "                sns.lineplot(x=column, y=target_variable, data=df, ax=ax, color=colors)\n",
    "                plt.xlabel(column)  \n",
    "                plt.ylabel(target_variable)  \n",
    "                plt.title(f\"Line Chart: {column} vs {target_variable}\")\n",
    "                st.pyplot(fig)\n",
    "                \n",
    "    elif chart_type == \"boxplot\":\n",
    "        if target_variable and selected_columns:\n",
    "            for column in selected_columns:\n",
    "                fig, ax = plt.subplots()\n",
    "                sns.boxplot(x=column, y=target_variable, data=df, ax=ax)\n",
    "                plt.xlabel(column)  \n",
    "                plt.ylabel(target_variable)  \n",
    "                plt.title(f\"Boxplot: {column} vs {target_variable}\")\n",
    "                st.pyplot(fig)\n",
    "    \n",
    "\n",
    "    elif chart_type == \"heatmap\":\n",
    "        numeric_df = df.select_dtypes(include=[np.number])\n",
    "        sns.heatmap(numeric_df.corr(), annot=True, ax=ax)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "    else:\n",
    "        st.error(\"Invalid chart type selected.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# Function to select and train the model\n",
    "def train_selected_model(X_train, y_train, selected_model):\n",
    "    if selected_model == 'Random Forest':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        \n",
    "    elif selected_model == 'SVM':\n",
    "        model = svm.SVC(random_state = 42)\n",
    "    \n",
    "    elif selected_model == \"XGBoost Classifier\":\n",
    "        model = xgb.XGBClassifier()\n",
    "    else:\n",
    "        st.write(\"Selected model is not supported.\")\n",
    "        return None\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    report = classification_report(y_test, predictions)\n",
    "    return cm, report\n",
    "\n",
    "        \n",
    "        \n",
    "# Streamlit Application \n",
    "st.title('Fraud Detection Tool')\n",
    "st.write('The application is designed for performing data cleaning, visualization, and fraud detection by model training.')\n",
    "\n",
    "# Add tabs for different functionalities\n",
    "tab1, tab2, tab3  = st.tabs([\"Data Cleaning\", \"Data Visualization\", \"Model Development\"])\n",
    "\n",
    "with tab1:\n",
    "    st.header('Data Cleaning')\n",
    "    st.write('Upload a dataset for data cleaning')\n",
    "    uploaded_file = st.file_uploader(\"Choose a file\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        st.write(df.head())\n",
    "        \n",
    "        # Identify columns with missing values\n",
    "        columns_with_missing = df.columns[df.isnull().any()].tolist()\n",
    "        if len(columns_with_missing) > 0:\n",
    "            st.write(\"Columns with missing values:\")\n",
    "            missing_data = df.isnull().sum()\n",
    "            total_values = df.shape[0]\n",
    "            for col in columns_with_missing:\n",
    "                missing_count = missing_data[col]\n",
    "                missing_percent = (missing_count / total_values) * 100\n",
    "                st.write(f\"{col}: {missing_count} missing values ({missing_percent:.2f}%)\")\n",
    "            \n",
    "            # Create a dictionary to store fill methods for each column\n",
    "            fill_methods = {}\n",
    "            for column in columns_with_missing:\n",
    "                fill_methods[column] = st.selectbox(f\"Select method to handle missing values for column '{column}':\", \n",
    "                                                    ['none', 'forward_fill', 'backward_fill', 'mean', 'median', 'mode'])\n",
    "\n",
    "            # Identify numeric columns for outlier removal\n",
    "            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            numeric_columns_with_outliers = st.multiselect(\"Select numeric columns for outlier removal:\", numeric_columns)\n",
    "            \n",
    "            \n",
    "            # Option for handling outliers\n",
    "            remove_outliers = st.checkbox(\"Remove outliers\")\n",
    "\n",
    "            # Options for data normalization/standardization\n",
    "            normalization = st.selectbox(\"Select Normalization/Standardization method:\", ['none', 'min_max', 'standard'])\n",
    "\n",
    "            \n",
    "\n",
    "            # Button to clean data\n",
    "            if st.button('Clean Data'):\n",
    "                df_clean = clean_data(df, fill_methods, numeric_columns_with_outliers, remove_outliers, normalization)\n",
    "                st.write(df_clean)\n",
    "\n",
    "                # Box plots to visualize data distribution before and after outlier removal\n",
    "                if remove_outliers:\n",
    "                    st.subheader(\"Box Plot before Outlier Removal\")\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    sns.boxplot(data=df[numeric_columns_with_outliers])\n",
    "                    st.pyplot()\n",
    "\n",
    "                    st.subheader(\"Box Plot after Outlier Removal\")\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    sns.boxplot(data=df_clean[numeric_columns_with_outliers])\n",
    "                    st.pyplot()\n",
    "\n",
    "                # Convert DataFrame to CSV and allow user to download\n",
    "                csv = df_clean.to_csv(index=False).encode('utf-8')\n",
    "                st.download_button(\n",
    "                    label=\"Download cleaned data as CSV\",\n",
    "                    data=csv,\n",
    "                    file_name='cleaned_data.csv',\n",
    "                    mime='text/csv',\n",
    "                )\n",
    "        else:\n",
    "            st.write(\"No missing values found in the dataset.\")\n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "with tab2:\n",
    "    with st.container():\n",
    "        st.header('Data Visualization')\n",
    "        st.write('Upload a dataset for making visualizations')\n",
    "        uploaded_file = st.file_uploader(\"Upload your dataset (.csv)\", type=\"csv\")\n",
    "\n",
    "        if uploaded_file is not None:\n",
    "            df = pd.read_csv(uploaded_file)\n",
    "\n",
    "            chart_type = st.selectbox(\"Choose chart type:\", [\"histogram\", \"bar chart\", \"line chart\", \"scatter plot\", \"boxplot\", \"heatmap\"])\n",
    "\n",
    "            selected_columns = []\n",
    "            target_variable = None\n",
    "\n",
    "            if chart_type in [\"histogram\", \"bar chart\", \"line chart\",\"boxplot\"]:\n",
    "                colors = st.color_picker(\"Choose color for the plot:\", \"#FF5733\")\n",
    "                selected_columns = st.multiselect('Select columns to visualize:', df.columns)\n",
    "\n",
    "            if chart_type in [\"bar chartbar\", \"line chart\", \"boxplot\"]:\n",
    "                target_variable = st.selectbox(\"Choose y-axis variable:\", [''] + list(df.columns))\n",
    "\n",
    "            if chart_type == \"scatter plot\":\n",
    "                colors = st.color_picker(\"Choose color for the plot:\", \"#FF5733\")\n",
    "                x_column = st.selectbox(\"Choose the X-axis variable:\", df.columns)\n",
    "                y_columns = st.multiselect(\"Choose the Y-axis variable(s):\", df.columns, default=df.columns[1])\n",
    "                hue_column = st.selectbox(\"Optional: Choose a variable for color coding (hue):\", [''] + list(df.columns))\n",
    "            if chart_type == \"heatmap\":\n",
    "                colors =    None\n",
    "\n",
    "            \n",
    "            if st.button('Generate Visualizations'):\n",
    "                generate_visualization(df, chart_type, selected_columns, target_variable, colors)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "with tab3:\n",
    "    st.header('Model Development')\n",
    "    st.write('Upload a dataset for model training')\n",
    "    uploaded_file = st.file_uploader(\"Upload your financial dataset\", key=\"model_development\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        df = df.iloc[:100000]\n",
    "        st.write(df.head())\n",
    "        \n",
    "        # Selection of features and target variable\n",
    "        all_columns = df.columns.tolist()\n",
    "        selected_features = st.multiselect('Select Features', all_columns, default=all_columns[:-1])\n",
    "        selected_target = st.selectbox('Select Target Variable', all_columns, index=len(all_columns)-1)\n",
    "        \n",
    "        # Convert categorical variables if necessary\n",
    "        st.write(\"After Encoding:\")\n",
    "        label_encoders = {}\n",
    "        for column in selected_features:\n",
    "            if df[column].dtype == 'object':\n",
    "                le = LabelEncoder()\n",
    "                df[column] = le.fit_transform(df[column])\n",
    "                label_encoders[column] = le\n",
    "        st.write(df)\n",
    "\n",
    "        \n",
    "        selected_model = st.selectbox('Select Algorithm', ['Random Forest', 'SVM', 'XGBoost Classifier'])\n",
    "        \n",
    "        if st.button('Train Model'):\n",
    "            X = df[selected_features]\n",
    "            y = df[selected_target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            model = train_selected_model(X_train, y_train, selected_model)\n",
    "            st.session_state.model = model\n",
    "            st.session_state.model_trained = True\n",
    "            \n",
    "            if model is not None:\n",
    "                st.session_state.model = model\n",
    "                st.session_state.model_trained = True\n",
    "                predictions = model.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, predictions)\n",
    "                report = classification_report(y_test, predictions)\n",
    "                cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "                # Model Evaluation \n",
    "                st.subheader('Model Evaluation')\n",
    "                st.write('**Accuracy:** {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "                # Classification Report\n",
    "                st.subheader('Classification Report')\n",
    "                st.text(report)\n",
    "\n",
    "                # Confusion matrix\n",
    "                st.subheader('Confusion Matrix')\n",
    "                fig, ax = plt.subplots()\n",
    "                sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='coolwarm', linewidths=0.5, linecolor='black')\n",
    "                plt.xlabel('Predicted', fontsize=12)\n",
    "                plt.ylabel('Atual', fontsize=12)\n",
    "                plt.title('Confusion Matrix', fontsize=14)\n",
    "                plt.xticks(fontsize=10)\n",
    "                plt.yticks(fontsize=10)\n",
    "                st.pyplot(fig)\n",
    "            \n",
    "        # Predict New Transactions\n",
    "        st.header('Predict New Transactions')\n",
    "        uploaded_sample = st.file_uploader(\"Upload Data to Predict New Transactions\", type=\".csv\")\n",
    "        if uploaded_sample is not None:\n",
    "            # Read the sample data using pandas\n",
    "            sample_df = pd.read_csv(uploaded_sample)\n",
    "            # Train a model on the sample data using selected features\n",
    "            sample_X = sample_df[selected_features]\n",
    "            st.write(sample_X.head())\n",
    "            \n",
    "            # Check if the model is trained\n",
    "            if st.session_state.model_trained == True:\n",
    "                for column in selected_features:\n",
    "                    if sample_X[column].dtype == 'object':\n",
    "                        le = label_encoders[column]\n",
    "                        sample_X[column] = le.transform(sample_X[column])\n",
    "                model = st.session_state.model \n",
    "                if st.button('Predict New Transactions'):\n",
    "                    predictions = model.predict(sample_X)\n",
    "                    # Combine predictions with original data\n",
    "                    sample_df['predictions'] = predictions\n",
    "                    st.write(sample_df.head()) \n",
    "                    # Save the combined DataFrame to CSV\n",
    "                    sample_df.to_csv('predictions.csv', index=False)\n",
    "                    st.success('Predictions saved to predictions.csv')\n",
    "            \n",
    "            else:\n",
    "                st.write(\"Please train a model first.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
